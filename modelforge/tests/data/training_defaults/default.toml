[training]
nr_of_epochs = 5
accelerator = "cpu"
num_nodes = 1
devices = 1                              # [0,1,2,3]
remove_self_energies = true
batch_size = 128
local_cache_dir = "./cache"

[training.training_parameter]
lr = 1e-3

[training.experiment_logger]
logger_name = "wandb"
save_dir = "test"
experiment_name = "{model_name}_{dataset_name}"

[training.training_parameter.lr_scheduler_config]
frequency = 1
mode = "min"
factor = 0.1
patience = 10
cooldown = 5
min_lr = 1e-8
threshold = 0.1
threshold_mode = "abs"
monitor = "val/per_molecule_energy/rmse"
interval = "epoch"

[training.training_parameter.loss_parameter]
loss_property = ['per_molecule_energy', 'per_atom_force'] # use .
[training.training_parameter.loss_parameter.weight]
per_molecule_energy = 0.999 #NOTE: reciproce units
per_atom_force = 0.001

[training.early_stopping]
verbose = true
monitor = "val/per_molecule_energy/rmse"
min_delta = 0.001
patience = 50
